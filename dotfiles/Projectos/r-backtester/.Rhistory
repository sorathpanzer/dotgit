# strings
rm_commas <- function(x) gsub(",", "", x)
provinces_confirmed <- provinces_confirmed %>% select(-starts_with("ExcludingHubei")) %>%
select(-starts_with("Hubei:")) %>% rename(Wuhan = "Wuhan,Hubei",
National = "National(confirmed)") %>% mutate(NationalSansHubei = excl_hubei,
HubeiSansWuhan = hubei_sans_wuhan, Date = ymd(Date), National = stringr::str_split(National,
"\\[", simplify = TRUE)[, 1], Hubei = stringr::str_split(Hubei,
"\\[", simplify = TRUE)[, 1], Wuhan = stringr::str_split(Wuhan,
"\\[", simplify = TRUE)[, 1]) %>% select(-contains("clinical",
ignore.case = TRUE)) %>% select(-contains("inclusive", ignore.case = TRUE)) %>%
filter(!is.na(Date)) %>% mutate_if(is.character, rm_commas) %>%
mutate_if(is.character, as.integer)
# work out the order for the columns from the data,
# descending order
province_order <- provinces_confirmed %>% pivot_longer(-Date,
names_to = "province", values_to = "incident_cases") %>%
group_by(province) %>% summarise(total = sum(incident_cases,
na.rm = TRUE)) %>% arrange(desc(total)) %>% pull(province)
# re-arrange the columns in the dataset and fill in some
# missing values, but not all, with zeroes.  Also,
# lab-confirmed and clinical counts for Wuhan are combined on
# the source Hubei health Commission from 15 Feb so set to NA
# since we cannot split out the lab-confirmed only
provinces_confirmed <- provinces_confirmed %>% select(c("Date",
province_order)) %>% arrange(Date) %>% mutate(National = ifelse(is.na(National),
0, National), Hubei = ifelse(is.na(Hubei), 0, Hubei), Wuhan = ifelse(is.na(Wuhan),
0, Wuhan)) %>% mutate(Wuhan = ifelse(Date >= ymd("2020-02-15"),
NA, Wuhan), HubeiSansWuhan = ifelse(Date >= ymd("2020-02-15"),
NA, HubeiSansWuhan))
# repeat for deaths parse the web page and extract the data
# from the second table
provinces_deaths <- outbreak_webpage %>% html_nodes("table") %>%
.[[2]] %>% html_table(fill = TRUE) %>% rename(Date = "Date (CST)")
# fix up the column names, get rid of footnotes and other
# non-data and convert columns to appropriate data types.
hubei_sans_wuhan <- provinces_deaths %>% select(starts_with("Hubei:")) %>%
select(-contains("clinical", ignore.case = TRUE)) %>% pull(1)
provinces_deaths <- provinces_deaths %>% select(-starts_with("Hubei:")) %>%
rename(Wuhan = "Wuhan,Hubei", National = "National(confirmed)") %>%
mutate(HubeiSansWuhan = hubei_sans_wuhan, Date = ymd(Date),
National = stringr::str_split(National, "\\[", simplify = TRUE)[,
1], Hubei = stringr::str_split(Hubei, "\\[", simplify = TRUE)[,
1], Wuhan = stringr::str_split(Wuhan, "\\[", simplify = TRUE)[,
1]) %>% select(-contains("clinical", ignore.case = TRUE)) %>%
select(-contains("inclusive", ignore.case = TRUE)) %>% filter(!is.na(Date)) %>%
mutate_if(is.character, rm_commas) %>% mutate_if(is.character,
as.integer) %>% mutate(NationalSansHubei = National - Hubei)
# work out the order for the columns from the data,
# descending order
province_order_deaths <- provinces_deaths %>% pivot_longer(-Date,
names_to = "province", values_to = "deaths_in_confirmed_cases") %>%
group_by(province) %>% summarise(total = sum(deaths_in_confirmed_cases,
na.rm = TRUE)) %>% arrange(desc(total)) %>% pull(province)
# re-arrange the columns in the dataset and fill in some
# missing values, but not all, with zeroes Also,
# lab-confirmed and clinical deaths for Wuhan are combined on
# the source Hubei health Commission from 15 Feb so set to NA
# since we cannot split out the deaths in lab-confirmed cases
# only
provinces_deaths <- provinces_deaths %>% select(c("Date", province_order_deaths)) %>%
arrange(Date) %>% mutate(National = ifelse(is.na(National),
0, National), Hubei = ifelse(is.na(Hubei), 0, Hubei), Wuhan = ifelse(is.na(Wuhan),
0, Wuhan)) %>% mutate(Wuhan = ifelse(Date >= ymd("2020-02-15"),
NA, Wuhan), HubeiSansWuhan = ifelse(Date >= ymd("2020-02-15"),
NA, HubeiSansWuhan))
# there are still issues with death counts in lab-confirmed
# after 12th Feb.  in particular the national count is less
# than tha Hubei count.  So we will just truncate the deaths
# at 12th Feb.
provinces_deaths <- provinces_deaths %>% filter(Date <= ymd("2020-02-12"))
destfile = "./assets/provinces_confirmed_jh.rda"
if (!file.exists(destfile)) {
provinces_confirmed_jh <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
rename(province = "Province/State", country_region = "Country/Region") %>%
pivot_longer(-c(province, country_region, Lat, Long),
names_to = "Date", values_to = "cumulative_cases") %>%
mutate(Date = as.Date(mdy_hm(paste(Date, "23:59", tz = "UTC")),
tz = "China/Beijing")) %>% filter(country_region ==
"Mainland China") %>% group_by(province) %>% arrange(province,
Date) %>% group_by(province) %>% mutate(incident_cases = c(0,
diff(cumulative_cases))) %>% ungroup() %>% select(-c(country_region,
Lat, Long, cumulative_cases)) %>% pivot_wider(Date, names_from = province,
values_from = incident_cases) %>% rename(InnerMongolia = "Inner Mongolia") %>%
mutate(source = "Johns Hopkins University")
save(provinces_confirmed_jh, file = destfile)
} else {
load(destfile)
}
compare_provinces_confirmed <- provinces_confirmed %>% mutate(source = "wikipedia") %>%
select(c(Date, source, names(provinces_confirmed_jh))) %>%
bind_rows(provinces_confirmed_jh) %>% arrange(Date, desc(source)) %>%
select(Date, source, everything())
compare_provinces_confirmed_long <- compare_provinces_confirmed %>%
filter(Date <= ymd("2020-02-12")) %>% pivot_longer(-c(Date,
source), names_to = "province", values_to = "incident_cases") %>%
filter(province %in% c("Hubei", "Beijing", "Guangdong", "Henan",
"Zhejiang", "Hunan", "Anhui", "Jiangxi", "Jiangsu", "Chongqing",
"Shandong"))
compare_provinces_confirmed_long %>% bind_rows(compare_provinces_confirmed_long %>%
group_by(Date, source) %>% summarise(incident_cases = sum(incident_cases,
na.rm = TRUE)) %>% mutate(province = "Sum all provinces")) %>%
ggplot(aes(x = Date, y = incident_cases, colour = source)) +
geom_line() + geom_point() + facet_grid(province ~ ., scale = "free_y") +
labs(y = "Daily incident confirmed cases", title = "Comparison of wikipedia and Johns Hopkins University\nCOVID-19 daily incidence data up to 12th February, 2020.",
subtitle = "(Note: not all provinces shown here)", caption = "Sources: Johns Hopkins CSSE Novel coronavirus COVID-19 (2019-nCoV) data repository\nat https://github.com/CSSEGISandData/COVID-19\nwikipedia: https://en.wikipedia.org/wiki/Timeline_of_the_2019–20_Wuhan_coronavirus_outbreak") +
theme(legend.position = "top", legend.title = element_blank())
library('xml2')
library('rvest')
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(quantstrat))
suppressPackageStartupMessages(library(highcharter))
suppressPackageStartupMessages(library(IKTrading))
suppressPackageStartupMessages(library(doParallel))
# download the wikipedia web page we use a specific version
# of the template page directly version of the wikipedia page
# that is used by this version of this document
wikipedia_data_url <- paste("https://en.wikipedia.org/w/index.php?title=Template:",
"2019–20_Wuhan_coronavirus_data/", "China_medical_cases_by_province&oldid=941235662",
sep = "")
outbreak_webpage <- read_html(wikipedia_data_url)
# parse the web page and extract the data from the first
# table
provinces_confirmed <- outbreak_webpage %>% html_nodes("table") %>%
.[[1]] %>% html_table(fill = TRUE) %>% rename(Date = "Date (CST)")
# fix up the column names, get rid of footnotes and other
# non-data and convert columns to appropriate data types.
excl_hubei <- provinces_confirmed %>% select(starts_with("ExcludingHubei")) %>%
pull(1)
hubei_sans_wuhan <- provinces_confirmed %>% select(starts_with("Hubei:")) %>%
select(-contains("clinical", ignore.case = TRUE)) %>% pull(1)
# utility function to remove commas in numbers as character
# strings
rm_commas <- function(x) gsub(",", "", x)
provinces_confirmed <- provinces_confirmed %>% select(-starts_with("ExcludingHubei")) %>%
select(-starts_with("Hubei:")) %>% rename(Wuhan = "Wuhan,Hubei",
National = "National(confirmed)") %>% mutate(NationalSansHubei = excl_hubei,
HubeiSansWuhan = hubei_sans_wuhan, Date = ymd(Date), National = stringr::str_split(National,
"\\[", simplify = TRUE)[, 1], Hubei = stringr::str_split(Hubei,
"\\[", simplify = TRUE)[, 1], Wuhan = stringr::str_split(Wuhan,
"\\[", simplify = TRUE)[, 1]) %>% select(-contains("clinical",
ignore.case = TRUE)) %>% select(-contains("inclusive", ignore.case = TRUE)) %>%
filter(!is.na(Date)) %>% mutate_if(is.character, rm_commas) %>%
mutate_if(is.character, as.integer)
# work out the order for the columns from the data,
# descending order
province_order <- provinces_confirmed %>% pivot_longer(-Date,
names_to = "province", values_to = "incident_cases") %>%
group_by(province) %>% summarise(total = sum(incident_cases,
na.rm = TRUE)) %>% arrange(desc(total)) %>% pull(province)
# re-arrange the columns in the dataset and fill in some
# missing values, but not all, with zeroes.  Also,
# lab-confirmed and clinical counts for Wuhan are combined on
# the source Hubei health Commission from 15 Feb so set to NA
# since we cannot split out the lab-confirmed only
provinces_confirmed <- provinces_confirmed %>% select(c("Date",
province_order)) %>% arrange(Date) %>% mutate(National = ifelse(is.na(National),
0, National), Hubei = ifelse(is.na(Hubei), 0, Hubei), Wuhan = ifelse(is.na(Wuhan),
0, Wuhan)) %>% mutate(Wuhan = ifelse(Date >= ymd("2020-02-15"),
NA, Wuhan), HubeiSansWuhan = ifelse(Date >= ymd("2020-02-15"),
NA, HubeiSansWuhan))
# repeat for deaths parse the web page and extract the data
# from the second table
provinces_deaths <- outbreak_webpage %>% html_nodes("table") %>%
.[[2]] %>% html_table(fill = TRUE) %>% rename(Date = "Date (CST)")
# fix up the column names, get rid of footnotes and other
# non-data and convert columns to appropriate data types.
hubei_sans_wuhan <- provinces_deaths %>% select(starts_with("Hubei:")) %>%
select(-contains("clinical", ignore.case = TRUE)) %>% pull(1)
provinces_deaths <- provinces_deaths %>% select(-starts_with("Hubei:")) %>%
rename(Wuhan = "Wuhan,Hubei", National = "National(confirmed)") %>%
mutate(HubeiSansWuhan = hubei_sans_wuhan, Date = ymd(Date),
National = stringr::str_split(National, "\\[", simplify = TRUE)[,
1], Hubei = stringr::str_split(Hubei, "\\[", simplify = TRUE)[,
1], Wuhan = stringr::str_split(Wuhan, "\\[", simplify = TRUE)[,
1]) %>% select(-contains("clinical", ignore.case = TRUE)) %>%
select(-contains("inclusive", ignore.case = TRUE)) %>% filter(!is.na(Date)) %>%
mutate_if(is.character, rm_commas) %>% mutate_if(is.character,
as.integer) %>% mutate(NationalSansHubei = National - Hubei)
# work out the order for the columns from the data,
# descending order
province_order_deaths <- provinces_deaths %>% pivot_longer(-Date,
names_to = "province", values_to = "deaths_in_confirmed_cases") %>%
group_by(province) %>% summarise(total = sum(deaths_in_confirmed_cases,
na.rm = TRUE)) %>% arrange(desc(total)) %>% pull(province)
# re-arrange the columns in the dataset and fill in some
# missing values, but not all, with zeroes Also,
# lab-confirmed and clinical deaths for Wuhan are combined on
# the source Hubei health Commission from 15 Feb so set to NA
# since we cannot split out the deaths in lab-confirmed cases
# only
provinces_deaths <- provinces_deaths %>% select(c("Date", province_order_deaths)) %>%
arrange(Date) %>% mutate(National = ifelse(is.na(National),
0, National), Hubei = ifelse(is.na(Hubei), 0, Hubei), Wuhan = ifelse(is.na(Wuhan),
0, Wuhan)) %>% mutate(Wuhan = ifelse(Date >= ymd("2020-02-15"),
NA, Wuhan), HubeiSansWuhan = ifelse(Date >= ymd("2020-02-15"),
NA, HubeiSansWuhan))
# there are still issues with death counts in lab-confirmed
# after 12th Feb.  in particular the national count is less
# than tha Hubei count.  So we will just truncate the deaths
# at 12th Feb.
provinces_deaths <- provinces_deaths %>% filter(Date <= ymd("2020-02-12"))
destfile = "./assets/provinces_confirmed_jh.rda"
if (!file.exists(destfile)) {
provinces_confirmed_jh <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv") %>%
rename(province = "Province/State", country_region = "Country/Region") %>%
pivot_longer(-c(province, country_region, Lat, Long),
names_to = "Date", values_to = "cumulative_cases") %>%
mutate(Date = as.Date(mdy_hm(paste(Date, "23:59", tz = "UTC")),
tz = "China/Beijing")) %>% filter(country_region ==
"Mainland China") %>% group_by(province) %>% arrange(province,
Date) %>% group_by(province) %>% mutate(incident_cases = c(0,
diff(cumulative_cases))) %>% ungroup() %>% select(-c(country_region,
Lat, Long, cumulative_cases)) %>% pivot_wider(Date, names_from = province,
values_from = incident_cases) %>% rename(InnerMongolia = "Inner Mongolia") %>%
mutate(source = "Johns Hopkins University")
save(provinces_confirmed_jh, file = destfile)
} else {
load(destfile)
}
compare_provinces_confirmed <- provinces_confirmed %>% mutate(source = "wikipedia") %>%
select(c(Date, source, names(provinces_confirmed_jh))) %>%
bind_rows(provinces_confirmed_jh) %>% arrange(Date, desc(source)) %>%
select(Date, source, everything())
compare_provinces_confirmed_long <- compare_provinces_confirmed %>%
filter(Date <= ymd("2020-02-12")) %>% pivot_longer(-c(Date,
source), names_to = "province", values_to = "incident_cases") %>%
filter(province %in% c("Hubei", "Beijing", "Guangdong", "Henan",
"Zhejiang", "Hunan", "Anhui", "Jiangxi", "Jiangsu", "Chongqing",
"Shandong"))
compare_provinces_confirmed_long %>% bind_rows(compare_provinces_confirmed_long %>%
group_by(Date, source) %>% summarise(incident_cases = sum(incident_cases,
na.rm = TRUE)) %>% mutate(province = "Sum all provinces")) %>%
ggplot(aes(x = Date, y = incident_cases, colour = source)) +
geom_line() + geom_point() + facet_grid(province ~ ., scale = "free_y") +
labs(y = "Daily incident confirmed cases", title = "Comparison of wikipedia and Johns Hopkins University\nCOVID-19 daily incidence data up to 12th February, 2020.",
subtitle = "(Note: not all provinces shown here)", caption = "Sources: Johns Hopkins CSSE Novel coronavirus COVID-19 (2019-nCoV) data repository\nat https://github.com/CSSEGISandData/COVID-19\nwikipedia: https://en.wikipedia.org/wiki/Timeline_of_the_2019–20_Wuhan_coronavirus_outbreak") +
theme(legend.position = "top", legend.title = element_blank())
install.packages("coronavirus")
library(coronavirus)
data("coronavirus")
library(coronavirus)
data("coronavirus")
head(coronavirus)
library(coronavirus)
library(dplyr)
summary_df <- coronavirus %>% group_by(Country.Region, type) %>%
summarise(total_cases = sum(cases)) %>%
arrange(-total_cases)
summary_df %>% head(20)
library(tidyr)
coronavirus %>%
filter(date == max(date)) %>%
select(country = Country.Region, type, cases) %>%
group_by(country, type) %>%
summarise(total_cases = sum(cases)) %>%
pivot_wider(names_from = type,
values_from = total_cases) %>%
arrange(-confirmed)
tail(coronavirus)
string(coronavirus)
library(coronavirus)
library(dplyr)
library(tidyr)
summary_df <- coronavirus %>% group_by(Country.Region, type) %>%
summarise(total_cases = sum(cases)) %>%
arrange(-total_cases)
summary_df %>% head(20)
coronavirus %>%
filter(date == max(date)) %>%
select(country = Country.Region, type, cases) %>%
group_by(country, type) %>%
summarise(total_cases = sum(cases)) %>%
pivot_wider(names_from = type,
values_from = total_cases) %>%
arrange(-confirmed)
library("swirl")
install.packages("swirl")
library("swirl")
library(swirl)
install.packages("Rcurl")
install.packages("RCurl")
install.packages("bitops")
update.packages()
install.packages("RCurl")
update.packages()
update.packages(ask=FALSE)
install.packages("swirl")
library(swirl)
swirl()
5 + 7
x <- 5 + 7
x
y <- x - 3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z* 2 + 100
my_sqrt <- sqrt(z) - 1
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- c(z / my_sqrt)
my_div <- z / my_sqrt
my_div
c(1, 2, 3, 4)
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(1, 10, 100)
c(1, 2, 3, 4) + c(0, 10, 100)
z* 2 + 1000
my_div
bye()
version()
version
version()
x <- c(2.23, 3.45, 1.87, 2.11, 7.33, 18.34, 19.23)
x
(2.23 + 3.45 + 1.87 + 2.11 + 7.33 + 18.34 + 19.23) / 7
version
versio()
versio()
version()
version()
swirl()
swirl
swirl()
library(swirl)
swirl()
bye
exit
quit
quit()
library(swirl)
swirl()
bye()
swirl()
exit()
quit()
swirl()
library(swirl)
swirl()
preview
preview()
help
help()
5 + 7
x <- 5 + 7
x
y <- x-3
y
z <- c(1.1, 9, 3.14)
?c
z
c(z, 555, z)
z * 2 + 100
my_sqrt sqrt(z -1)
my_sqrt <- sqrt(z -1)
my_sqrt
my_div <- z / my_sqrt
my_div
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
c(1, 2, 3, 4) + c(0, 10, 1000)
(z * 2 + 1000)
z * 2 + 1000
my_div
quit()
library(dplyr)
quit()
library(tidyverse)
library(ggplot2)
install.packages(tidyverse)
install.packages("tidyverse")
library(ggplot2)
library(tidyverse)
quit()
install.packages("Rcpp")
install.packages("PerformanceAnalytics")
quit()
library(tidyverse)
library(highcharter)
library(IKTrading)
update.packages()
library(Rcpp)
suppressPackageStartupMessages(library(knitr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(quantstrat))
suppressPackageStartupMessages(library(highcharter))
suppressPackageStartupMessages(library(IKTrading))
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(dplyr))
t1 <- Sys.time()
registerDoParallel(cores=detectCores())
# ---------------------------------------------------- #
t1 <- Sys.time()
init_date <- "2004-10-25 01:00:00"
init_equity <- 200
start_date <- "2005::"
stoploss <- 0.24
profitLong <- 1.8
profitSell <- 7.4
emaF <- 8  #S->8   || B->3
emaM <- 28  #S->28  || B->4
emaS <- 195 #S->195 || B-> 22
wdayBuy <- c(2,4,5,7) #c(2,4,5,7)
wdaySell <- c(1,6)    #c(1,6)
# ---------------------------------------------------- #
setwd("/home/sorath/Projectos/r-backtester")
Sys.setenv(TZ = "UTC")
currency("EUR")
portfolio.st <- "Port.Luxor"
account.st <- "Acct.Luxor"
strategy.st <- "Strat.Luxor"
rm.strat(portfolio.st)
rm.strat(account.st)
source("heikin.R")
source("myblotter.R")
source("strat.R")
source("rules.R")
rets <- PortfReturns(Account = account.st)
txs <- as.data.frame(getTxns(portfolio.st, symbols))[-c(1),]
txsClosed <- txs[ c(FALSE,TRUE),]
LS_Stats <- function(y) {
if (y == "long") {
pos <- -1
side <- c("Total (Long)", "SumProfit (Long)", "SumLoss (Long)", "ProfitFactor (Long)")
} else if (y == "short") {
pos <- 1
side <- c("Total (Short)", "SumProfit (Short)", "SumLoss (Short)", "ProfitFactor (Short)")}
txs.Profit <- txsClosed[txsClosed$Txn.Qty == pos & txsClosed$Net.Txn.Realized.PL >= 0, ]
txs.Loss <- txsClosed[txsClosed$Txn.Qty == pos & txsClosed$Net.Txn.Realized.PL < 0, ]
SumProfit <- sum(txs.Profit["Net.Txn.Realized.PL"])
SumLoss <- sum(txs.Loss["Net.Txn.Realized.PL"])
SumTxs <- SumProfit+SumLoss
ProfitFactor <- abs(SumProfit/SumLoss)
TotalStats <- side
Values <- c(SumTxs, SumProfit, SumLoss, ProfitFactor)
data.frame(TotalStats, Values)
}
sumTrades <- function(x) {
if (x == "long") {
pos <- 1
} else if (x == "short") {
pos <- -1}
listLong <- txsClosed[txsClosed$Txn.Qty == pos & txsClosed$Net.Txn.Realized.PL >= 0, ]
cumsum(listLong["Net.Txn.Realized.PL"])
}
orders <- as.data.frame(getOrders(portfolio.st, symbols, status = "closed"))
ordersCols <- orders[,c("Order.Qty", "Order.Price",	"Order.Type",	"Order.Side",	"Order.Threshold",	"Order.Status", "Order.StatusTime",	"Order.Set",	"Rule",	"Time.In.Force")]
tbind <- cbind(txs, ordersCols)
startOrders <- tbind[ c(TRUE,FALSE), ]
endOrders <- tbind[ c(FALSE,TRUE), ]
sID <- startOrders[,c("Txn.Price","Order.Side","Rule")]
startOrdersFilter <- cbind(sID, "ID"=1:nrow(sID))
eID <- endOrders[,c("Txn.Price","Rule")] %>%
rename(
"Txn.Price.Close" = Txn.Price,
"Rule.Close" = Rule)
endOrdersFilter <- cbind(eID, "ID"=1:nrow(eID))
bindThem <- merge(data.frame(startOrdersFilter, row.names=NULL), data.frame(endOrdersFilter, row.names=NULL), by = "ID", all = TRUE)[-1]
cleanThem <- bindThem[!is.na(bindThem$Rule.Close),]
tradeStats <- perTradeStats(portfolio.st, symbols, includeOpenTrade = FALSE)
tradeStatsFilter <- tradeStats[,c("Start", "End","Net.Trading.PL", "Pct.Net.Trading.PL", "duration")]
tradeStatsMerge <- cbind(tradeStatsFilter,cleanThem)
tradeStatsOrder <- tradeStatsMerge[,c("Start", "End", "Order.Side", "Txn.Price", "Rule", "Net.Trading.PL",	"Pct.Net.Trading.PL", "Txn.Price.Close", "Rule.Close", "duration")] %>%
rename(
Position = Order.Side,
"Entry.Price" = Txn.Price,
"Entry.Rule" = Rule,
"PL" = Net.Trading.PL,
"PL (%)" = Pct.Net.Trading.PL,
"Close.Price" = Txn.Price.Close,
"Close Rule" = Rule.Close,
"Duration" = duration)
arTab <- table.AnnualizedReturns(rets)
max.risk <- max(arTab["Annualized Std Dev",])
max.return <- max(arTab["Annualized Return",])
a <- getAccount(account.st)
equity = a$summary$End.Eq[start_date]
chart.Posn(portfolio.st, Symbol = symbols)
quanTiles <- tradeQuantiles(portfolio.st, symbols, scale = c("cash", "percent", "tick"),
probs = c(0.5, 0.75, 0.9, 1))
chart.ME(Portfolio=portfolio.st, Symbol=symbols, type='MAE', scale='cash')
chart.ME(Portfolio=portfolio.st, Symbol=symbols, type='MFE', scale='cash')
chart.Boxplot(rets, main = "EURUSD Returns", colorset= rich10equal)
charts.PerformanceSummary(apply.monthly(rets, Return.cumulative),
colorset = bluefocus, main = "Strategy Performance")
chart.RiskReturnScatter(rets,
main = "EURUSD Performance", colorset = rich10equal,
xlim = c(0, max.risk * 1.1), ylim = c(0, max.return))
chart.RiskReturnScatter(rets, Rf = 0, add.sharpe = c(1, 2),
main = "Return vs. Risk", colorset = c("red", "blue"))
quanTiles <- tradeQuantiles(portfolio.st, symbols, scale = c("cash", "percent", "tick"),
probs = c(0.5, 0.75, 0.9, 1))
hchart(equity, color = "black", name = "PL") %>%
hc_title(text = "Equity")
tradeStatsOrder$weekday <- wday(tradeStatsOrder[,1])
tradeStatsOrder
monday <- filter(tradeStatsOrder, weekday == '1')
sum(monday$PL)
source("highchart.R")
chartplot
kable(t(dailyStats(portfolio.st)))
kable(t(tradeStats(portfolio.st)))
kable(LS_Stats("long"))
kable(LS_Stats("short"))
yearlyReturn(equity) * 200
t2 <- Sys.time()
print(t2-t1)
